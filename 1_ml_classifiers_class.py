# -*- coding: utf-8 -*-
"""1_ml_classifiers_class.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qo0L9V0GRgO2a_hlj80qTI4fbe4sq1HO

binary classifier
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('exercise1.csv')

df.head()

df.shape

df['target'].unique()

df['target'].value_counts()

df.describe()

# 데이터 시각화
nrows, ncols = 2, 3
fig, axs = plt.subplots(nrows=nrows, ncols=ncols)
fig.set_size_inches(10,6)

for i in range(nrows):
    for j in range(ncols):
        attr = i * ncols + j
        sns.histplot(x=df.columns[attr], data=df, hue = 'target', ax=axs[i][j])

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

# 1. 데이터 분할 
X = df.iloc[:, :6]
y = df['target']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)

# 2. 모델 인스턴스 생성
model = DecisionTreeClassifier(random_state=42)

# 3. 모델 학습
model.fit(X_train, y_train)

# 4. 모델 평가
y_pred = model.predict(X_test)
accuracy_score(y_test, y_pred)

from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier

# 2. 모델 인스턴스 생성
rf_cls = RandomForestClassifier(random_state=42)
gb_cls = GradientBoostingClassifier(random_state=42)
xgb_cls = XGBClassifier(random_state=42)
lgb_cls = LGBMClassifier(random_state=42)

# 3. 모델 학습
rf_cls.fit(X_train, y_train)
gb_cls.fit(X_train, y_train)
xgb_cls.fit(X_train, y_train)
lgb_cls.fit(X_train, y_train)

# 4. 모델 평가
y_pred_rf = rf_cls.predict(X_test)
y_pred_gb = gb_cls.predict(X_test)
y_pred_xgb = xgb_cls.predict(X_test)
y_pred_lgb = lgb_cls.predict(X_test)

print('RandomForest accuracy:{}'.format(accuracy_score(y_test, y_pred_rf)))
print('GB accuracy:{}'.format(accuracy_score(y_test, y_pred_gb)))
print('XGB accuracy:{}'.format(accuracy_score(y_test, y_pred_xgb)))
print('LGB accuracy:{}'.format(accuracy_score(y_test, y_pred_lgb)))

from sklearn.svm import SVC
svc = SVC()
svc.fit(X_train, y_train)
y_pred = svc.predict(X_test)
accuracy_score(y_test, y_pred)

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
X_scale = sc.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size = 0.2, random_state = 42, stratify = y)

svc = SVC()
svc.fit(X_train, y_train)
y_pred = svc.predict(X_test)
accuracy_score(y_test, y_pred)